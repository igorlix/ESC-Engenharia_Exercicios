{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Classificador de Spam usando Machine Learning\n\nEste notebook implementa um modelo de classificação de mensagens SMS como spam ou não spam.\n\n**Pipeline do projeto:**\n1. Carregamento de dados textuais (mensagens SMS)\n2. Análise exploratória (ainda trabalhando com texto)\n3. Pré-processamento com primeira tokenização manual\n4. Vetorização TF-IDF que transforma texto em dados numéricos\n5. Treinamento do modelo com dados numéricos\n6. Avaliação e testes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Carregamento dos Dados\n\nNesta etapa trabalhamos com **dados textuais** (mensagens SMS em formato de string). O objetivo é carregar o dataset e preparar as colunas para análise."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "\n",
    "df = df[['v1', 'v2']]\n",
    "df.columns = ['categoria', 'mensagem']\n",
    "\n",
    "print(f'Total de mensagens: {len(df)}')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Análise Exploratória\n\nAinda trabalhando com **dados textuais**, fazemos análise descritiva para entender:\n- Distribuição de classes (spam vs não spam)\n- Tamanho médio das mensagens\n- Padrões visuais nos dados\n\nApenas calculamos estatísticas sobre o texto, sem transformá-lo ainda."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nDistribuição das categorias:')\n",
    "print(df['categoria'].value_counts())\n",
    "print(f'\\nPercentual de spam: {(df[\"categoria\"] == \"spam\").sum() / len(df) * 100:.2f}%')\n",
    "print(f'Percentual de ham: {(df[\"categoria\"] == \"ham\").sum() / len(df) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "df['categoria'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Quantidade de Mensagens por Categoria')\n",
    "axes[0].set_xlabel('Categoria')\n",
    "axes[0].set_ylabel('Quantidade')\n",
    "axes[0].set_xticklabels(['Não Spam', 'Spam'], rotation=0)\n",
    "\n",
    "df['tamanho'] = df['mensagem'].apply(len)\n",
    "df.boxplot(column='tamanho', by='categoria', ax=axes[1])\n",
    "axes[1].set_title('Tamanho das Mensagens por Categoria')\n",
    "axes[1].set_xlabel('Categoria')\n",
    "axes[1].set_ylabel('Número de caracteres')\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nEstatísticas do tamanho das mensagens:')\n",
    "print(df.groupby('categoria')['tamanho'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Pré-processamento de Texto\n\nAqui ocorre a **primeira tokenização** do texto. Tokenização é o processo de dividir o texto em unidades menores (tokens/palavras).\n\n**Por que tokenizar?**\n- Modelos de ML não entendem texto direto\n- Precisamos quebrar em palavras individuais para análise\n- Permite remover palavras irrelevantes (stopwords)\n- Facilita normalização e stemming\n\n**Processo:**\n1. `lower()` - Converte para minúsculas\n2. `re.sub()` - Remove pontuação e caracteres especiais\n3. `split()` - **TOKENIZAÇÃO**: divide texto em lista de palavras\n4. Remoção de stopwords (palavras comuns como \"the\", \"is\", \"a\")\n5. Stemming: reduz palavras à raiz (ex: \"running\" → \"run\")\n\nAinda são **dados textuais**, mas limpos e normalizados."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocessar_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
    "    palavras = texto.split()\n",
    "    palavras = [stemmer.stem(palavra) for palavra in palavras if palavra not in stop_words]\n",
    "    return ' '.join(palavras)\n",
    "\n",
    "df['mensagem_processada'] = df['mensagem'].apply(preprocessar_texto)\n",
    "\n",
    "print('Exemplo de pré-processamento:')\n",
    "print(f'\\nOriginal: {df.iloc[3][\"mensagem\"]}')\n",
    "print(f'\\nProcessada: {df.iloc[3][\"mensagem_processada\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Preparação dos Dados para Treinamento\n\n### Transformação de Texto em Dados Numéricos\n\n**MOMENTO CRÍTICO**: Aqui os dados textuais são transformados em **dados numéricos**.\n\n**TfidfVectorizer** faz:\n1. **Segunda tokenização** (mais sofisticada que a primeira)\n2. Cria um vocabulário com as 3000 palavras mais importantes\n3. Transforma cada mensagem em um vetor numérico de 3000 dimensões\n4. Calcula o peso TF-IDF para cada palavra\n\n**TF-IDF = Term Frequency × Inverse Document Frequency**\n- Palavras raras mas frequentes na mensagem ganham peso alto\n- Palavras comuns em todas mensagens ganham peso baixo\n\n**Exemplo:**\n```\nTexto: \"win free prize now\"\nVetor: [0, 0, 0.85, 0, 0.92, 0, 0.73, 0, ...]\n              ↑        ↑        ↑\n            \"win\"   \"free\"  \"prize\"\n```\n\nA partir daqui trabalhamos apenas com **dados numéricos** (matrizes TF-IDF)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['mensagem_processada']\n",
    "y = df['categoria'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f'Tamanho do conjunto de treino: {len(X_treino)}')\n",
    "print(f'Tamanho do conjunto de teste: {len(X_teste)}')\n",
    "print(f'\\nDistribuição no treino:')\n",
    "print(y_treino.value_counts())\n",
    "print(f'\\nDistribuição no teste:')\n",
    "print(y_teste.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizador = TfidfVectorizer(max_features=3000)\n",
    "\n",
    "X_treino_tfidf = vetorizador.fit_transform(X_treino)\n",
    "X_teste_tfidf = vetorizador.transform(X_teste)\n",
    "\n",
    "print(f'Shape da matriz TF-IDF de treino: {X_treino_tfidf.shape}')\n",
    "print(f'Shape da matriz TF-IDF de teste: {X_teste_tfidf.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Treinamento do Modelo\n\nO modelo Naive Bayes é treinado com os **dados numéricos** (vetores TF-IDF).\n\nEle aprende a probabilidade de cada palavra estar associada a spam ou não spam baseado nos padrões numéricos dos dados de treino."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MultinomialNB()\n",
    "modelo.fit(X_treino_tfidf, y_treino)\n",
    "\n",
    "print('Modelo treinado com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Avaliação do Modelo\n\nTestamos o modelo com **dados numéricos** nunca vistos (conjunto de teste).\n\n**Métricas importantes:**\n- **Acurácia**: % de acertos totais\n- **Precisão**: dos que prevemos como spam, quantos realmente eram spam\n- **Recall**: de todos os spams reais, quantos conseguimos detectar\n- **F1-Score**: média harmônica entre precisão e recall"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_treino = modelo.predict(X_treino_tfidf)\n",
    "y_pred_teste = modelo.predict(X_teste_tfidf)\n",
    "\n",
    "print('=== DESEMPENHO NO CONJUNTO DE TREINO ===')\n",
    "print(f'Acurácia: {accuracy_score(y_treino, y_pred_treino):.4f}')\n",
    "print(f'Precisão: {precision_score(y_treino, y_pred_treino):.4f}')\n",
    "print(f'Recall: {recall_score(y_treino, y_pred_treino):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_treino, y_pred_treino):.4f}')\n",
    "\n",
    "print('\\n=== DESEMPENHO NO CONJUNTO DE TESTE ===')\n",
    "print(f'Acurácia: {accuracy_score(y_teste, y_pred_teste):.4f}')\n",
    "print(f'Precisão: {precision_score(y_teste, y_pred_teste):.4f}')\n",
    "print(f'Recall: {recall_score(y_teste, y_pred_teste):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_teste, y_pred_teste):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nRelatório de Classificação Completo:')\n",
    "print(classification_report(y_teste, y_pred_teste, target_names=['Não Spam', 'Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusao = confusion_matrix(y_teste, y_pred_teste)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matriz_confusao, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Não Spam', 'Spam'], \n",
    "            yticklabels=['Não Spam', 'Spam'])\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Previsto')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nVerdadeiros Negativos: {matriz_confusao[0, 0]}')\n",
    "print(f'Falsos Positivos: {matriz_confusao[0, 1]}')\n",
    "print(f'Falsos Negativos: {matriz_confusao[1, 0]}')\n",
    "print(f'Verdadeiros Positivos: {matriz_confusao[1, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Função para Classificar Novas Mensagens\n\nEsta função recebe **texto** e executa todo o pipeline:\n1. Pré-processamento (tokenização manual)\n2. Vetorização TF-IDF (conversão para dados numéricos)\n3. Predição usando o modelo treinado\n4. Retorna classificação e probabilidades"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificar_mensagem(mensagem):\n",
    "    mensagem_processada = preprocessar_texto(mensagem)\n",
    "    mensagem_tfidf = vetorizador.transform([mensagem_processada])\n",
    "    predicao = modelo.predict(mensagem_tfidf)[0]\n",
    "    probabilidade = modelo.predict_proba(mensagem_tfidf)[0]\n",
    "    \n",
    "    resultado = 'SPAM' if predicao == 1 else 'NÃO SPAM'\n",
    "    confianca = probabilidade[predicao] * 100\n",
    "    \n",
    "    print(f'Mensagem: \"{mensagem}\"')\n",
    "    print(f'Classificação: {resultado}')\n",
    "    print(f'Confiança: {confianca:.2f}%')\n",
    "    print(f'Probabilidades -> Não Spam: {probabilidade[0]:.4f} | Spam: {probabilidade[1]:.4f}')\n",
    "    print('-' * 80)\n",
    "    \n",
    "    return resultado, confianca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Testando o Classificador com Novas Mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens_teste = [\n",
    "    \"Congratulations! You've won a free ticket to the Bahamas. Call now!\",\n",
    "    \"Hey, are we still meeting for lunch tomorrow?\",\n",
    "    \"URGENT! Your account will be closed. Click here immediately to verify.\",\n",
    "    \"Can you pick up some milk on your way home?\",\n",
    "    \"You have been selected for a special offer. Text WIN to 12345.\",\n",
    "    \"Thanks for your help yesterday, really appreciate it!\"\n",
    "]\n",
    "\n",
    "print('\\n=== TESTANDO O CLASSIFICADOR ===')\n",
    "print()\n",
    "for msg in mensagens_teste:\n",
    "    classificar_mensagem(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Análise das Palavras Mais Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "feature_names = vetorizador.get_feature_names_out()\nlog_prob_spam = modelo.feature_log_prob_[1]\nlog_prob_ham = modelo.feature_log_prob_[0]\n\nindices_spam = np.argsort(log_prob_spam)[-20:]\nindices_ham = np.argsort(log_prob_ham)[-20:]\n\npalavras_spam = [feature_names[i] for i in indices_spam]\npalavras_ham = [feature_names[i] for i in indices_ham]\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\naxes[0].barh(range(len(palavras_spam)), [log_prob_spam[i] for i in indices_spam], color='#e74c3c')\naxes[0].set_yticks(range(len(palavras_spam)))\naxes[0].set_yticklabels(palavras_spam)\naxes[0].set_xlabel('Log Probabilidade')\naxes[0].set_title('Top 20 Palavras Associadas a SPAM')\n\naxes[1].barh(range(len(palavras_ham)), [log_prob_ham[i] for i in indices_ham], color='#2ecc71')\naxes[1].set_yticks(range(len(palavras_ham)))\naxes[1].set_yticklabels(palavras_ham)\naxes[1].set_xlabel('Log Probabilidade')\naxes[1].set_title('Top 20 Palavras Associadas a NÃO SPAM')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Testando com Mensagens em Português\n\nComo o modelo foi treinado com mensagens em inglês, precisamos traduzir mensagens em português antes de classificar.\n\n**Pipeline para português:**\n1. Mensagem em português (**texto**)\n2. Tradução para inglês usando Google Translate (**texto**)\n3. Pré-processamento (**texto tokenizado**)\n4. Vetorização TF-IDF (**dados numéricos**)\n5. Classificação pelo modelo",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from googletrans import Translator\n\ntradutor = Translator()\n\ndef traduzir_mensagem(texto, destino='en'):\n    try:\n        resultado = tradutor.translate(texto, dest=destino)\n        return resultado.text\n    except:\n        return texto",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "mensagens_teste_pt = [\n    \"Parabéns! Você ganhou um prêmio de R$ 10.000. Ligue agora para resgatar!\",\n    \"Oi, vamos nos encontrar para almoçar amanhã?\",\n    \"URGENTE! Sua conta será bloqueada. Clique aqui imediatamente para verificar.\",\n    \"Pode comprar leite quando estiver voltando para casa?\",\n    \"Você foi selecionado para uma oferta especial. Responda SIM para 40404.\",\n    \"Obrigado pela ajuda ontem, agradeço muito!\"\n]\n\nprint('=== CLASSIFICANDO MENSAGENS EM PORTUGUÊS ===\\n')\n\nfor msg_pt in mensagens_teste_pt:\n    print(f'Mensagem original (PT): \"{msg_pt}\"')\n    msg_en = traduzir_mensagem(msg_pt, destino='en')\n    print(f'Traduzida (EN): \"{msg_en}\"')\n    print()\n    classificar_mensagem(msg_en)\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}