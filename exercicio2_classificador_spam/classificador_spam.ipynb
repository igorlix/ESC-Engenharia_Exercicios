{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador de Spam usando Machine Learning\n",
    "\n",
    "Este notebook implementa um modelo de classificação de mensagens SMS como spam ou não spam.\n",
    "\n",
    "**Etapas:**\n",
    "1. Carregamento dos dados \n",
    "2. Análise exploratória \n",
    "3. Pré-processamento \n",
    "4. Vetorização que transforma texto em dados numéricos\n",
    "5. Treinamento do modelo com dados numéricos\n",
    "6. Avaliação e testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados\n",
    "\n",
    "Nesta etapa utilizo **dados textuais** (mensagens SMS em formato de string). O objetivo é carregar o dataset e preparar as colunas para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "\n",
    "df = df[['v1', 'v2']]\n",
    "df.columns = ['categoria', 'mensagem']\n",
    "\n",
    "print(f'Total de mensagens: {len(df)}')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória\n",
    "\n",
    "- Distribuição de classes (spam vs não spam)\n",
    "- Tamanho médio das mensagens\n",
    "- Padrões visuais nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nDistribuição das categorias:')\n",
    "print(df['categoria'].value_counts())\n",
    "print(f'\\nPercentual de spam: {(df[\"categoria\"] == \"spam\").sum() / len(df) * 100:.2f}%')\n",
    "print(f'Percentual de ham: {(df[\"categoria\"] == \"ham\").sum() / len(df) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "df['categoria'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Quantidade de Mensagens por Categoria')\n",
    "axes[0].set_xlabel('Categoria')\n",
    "axes[0].set_ylabel('Quantidade')\n",
    "axes[0].set_xticklabels(['Não Spam', 'Spam'], rotation=0)\n",
    "\n",
    "df['tamanho'] = df['mensagem'].apply(len)\n",
    "df.boxplot(column='tamanho', by='categoria', ax=axes[1])\n",
    "axes[1].set_title('Tamanho das Mensagens por Categoria')\n",
    "axes[1].set_xlabel('Categoria')\n",
    "axes[1].set_ylabel('Número de caracteres')\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nEstatísticas do tamanho das mensagens:')\n",
    "print(df.groupby('categoria')['tamanho'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento de Texto\n",
    "\n",
    "Aqui ocorre a **primeira tokenização** do texto.\n",
    "\n",
    "**Processo:**\n",
    "1. `lower()`: Converte para minúsculas\n",
    "2. `re.sub()`: Remove pontuação e caracteres especiais\n",
    "3. `split()`: divide texto em lista de palavras\n",
    "4. Remoção de stopwords (palavras comuns como \"the\", \"is\", \"a\")\n",
    "5. Stemming: reduz palavras à raiz (ex: \"running\" → \"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocessar_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
    "    palavras = texto.split()\n",
    "    palavras = [stemmer.stem(palavra) for palavra in palavras if palavra not in stop_words]\n",
    "    return ' '.join(palavras)\n",
    "\n",
    "df['mensagem_processada'] = df['mensagem'].apply(preprocessar_texto)\n",
    "\n",
    "print('Exemplo de pré-processamento:')\n",
    "print(f'\\nOriginal: {df.iloc[3][\"mensagem\"]}')\n",
    "print(f'\\nProcessada: {df.iloc[3][\"mensagem_processada\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparação dos Dados para Treinamento\n",
    "\n",
    "### Transformação de Texto em Dados Numéricos\n",
    "\n",
    "\n",
    "\n",
    "**TfidfVectorizer**:\n",
    "1. Cria um vocabulário com as 3000 palavras mais importantes\n",
    "2. Transforma cada mensagem em um vetor numérico de 3000 dimensões\n",
    "3. Calcula o peso TF-IDF para cada palavra\n",
    "\n",
    "**TF-IDF = Term Frequency × Inverse Document Frequency**\n",
    "- Palavras raras mas frequentes na mensagem ganham peso alto\n",
    "- Palavras comuns em todas mensagens ganham peso baixo\n",
    "\n",
    "**Exemplo:**\n",
    "```\n",
    "Texto: \"win free prize now\"\n",
    "Vetor: [0, 0, 0.85, 0, 0.92, 0, 0.73, 0, ...]\n",
    "              ↑        ↑        ↑\n",
    "            \"win\"   \"free\"  \"prize\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['mensagem_processada']\n",
    "y = df['categoria'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f'Tamanho do conjunto de treino: {len(X_treino)}')\n",
    "print(f'Tamanho do conjunto de teste: {len(X_teste)}')\n",
    "print(f'\\nDistribuição no treino:')\n",
    "print(y_treino.value_counts())\n",
    "print(f'\\nDistribuição no teste:')\n",
    "print(y_teste.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizador = TfidfVectorizer(max_features=3000)\n",
    "\n",
    "X_treino_tfidf = vetorizador.fit_transform(X_treino)\n",
    "X_teste_tfidf = vetorizador.transform(X_teste)\n",
    "\n",
    "print(f'Shape da matriz TF-IDF de treino: {X_treino_tfidf.shape}')\n",
    "print(f'Shape da matriz TF-IDF de teste: {X_teste_tfidf.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Treinamento do Modelo\n",
    "\n",
    "O modelo Naive Bayes é treinado com os **dados numéricos** (vetores TF-IDF).\n",
    "\n",
    "Ele aprende a probabilidade de cada palavra estar associada a spam ou não spam baseado nos padrões numéricos dos dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MultinomialNB()\n",
    "modelo.fit(X_treino_tfidf, y_treino)\n",
    "\n",
    "print('Modelo treinado com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Avaliação do Modelo\n",
    "\n",
    "Aqui testo o modelo com **dados numéricos** nunca vistos (conjunto de teste).\n",
    "\n",
    "**Métricas:**\n",
    "- **Acurácia**: % de acertos totais\n",
    "- **Precisão**: dos que prevemos como spam, quantos realmente eram spam\n",
    "- **Recall**: de todos os spams reais, quantos conseguimos detectar\n",
    "- **F1-Score**: média harmônica entre as duas últimas métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_treino = modelo.predict(X_treino_tfidf)\n",
    "y_pred_teste = modelo.predict(X_teste_tfidf)\n",
    "\n",
    "print('Desempenho no Treino')\n",
    "print(f'Acurácia: {accuracy_score(y_treino, y_pred_treino):.4f}')\n",
    "print(f'Precisão: {precision_score(y_treino, y_pred_treino):.4f}')\n",
    "print(f'Recall: {recall_score(y_treino, y_pred_treino):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_treino, y_pred_treino):.4f}')\n",
    "\n",
    "print('\\nDesempenho no Teste')\n",
    "print(f'Acurácia: {accuracy_score(y_teste, y_pred_teste):.4f}')\n",
    "print(f'Precisão: {precision_score(y_teste, y_pred_teste):.4f}')\n",
    "print(f'Recall: {recall_score(y_teste, y_pred_teste):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_teste, y_pred_teste):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nRelatório de Classificação:')\n",
    "print(classification_report(y_teste, y_pred_teste, target_names=['Não Spam', 'Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusao = confusion_matrix(y_teste, y_pred_teste)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matriz_confusao, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Não Spam', 'Spam'], \n",
    "            yticklabels=['Não Spam', 'Spam'])\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Valor Previsto')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nVerdadeiros Negativos: {matriz_confusao[0, 0]}')\n",
    "print(f'Falsos Positivos: {matriz_confusao[0, 1]}')\n",
    "print(f'Falsos Negativos: {matriz_confusao[1, 0]}')\n",
    "print(f'Verdadeiros Positivos: {matriz_confusao[1, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Função para Classificar Novas Mensagens\n",
    "\n",
    "Esta função recebe **texto** e executa todo o pipeline:\n",
    "1. Pré-processamento \n",
    "2. Vetorização TF-IDF \n",
    "3. Predição usando o modelo treinado\n",
    "4. Retorna classificação e probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificar_mensagem(mensagem):\n",
    "    mensagem_processada = preprocessar_texto(mensagem)\n",
    "    mensagem_tfidf = vetorizador.transform([mensagem_processada])\n",
    "    predicao = modelo.predict(mensagem_tfidf)[0]\n",
    "    probabilidade = modelo.predict_proba(mensagem_tfidf)[0]\n",
    "    \n",
    "    resultado = 'SPAM' if predicao == 1 else 'NÃO SPAM'\n",
    "    confianca = probabilidade[predicao] * 100\n",
    "    \n",
    "    print(f'Mensagem: \"{mensagem}\"')\n",
    "    print(f'Classificação: {resultado}')\n",
    "    print(f'Confiança: {confianca:.2f}%')\n",
    "    print(f'Probabilidades -> Não Spam: {probabilidade[0]:.4f} | Spam: {probabilidade[1]:.4f}')\n",
    "    print('-' * 80)\n",
    "    \n",
    "    return resultado, confianca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Testando o Classificador com Novas Mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens_teste = [\n",
    "    \"Congratulations! You've won a free ticket to the Bahamas. Call now!\",\n",
    "    \"Hey, are we still meeting for lunch tomorrow?\",\n",
    "    \"URGENT! Your account will be closed. Click here immediately to verify.\",\n",
    "    \"Can you pick up some milk on your way home?\",\n",
    "    \"You have been selected for a special offer. Text WIN to 12345.\",\n",
    "    \"Thanks for your help yesterday, really appreciate it!\"\n",
    "]\n",
    "\n",
    "print('\\nTestando o Classificador')\n",
    "print()\n",
    "for msg in mensagens_teste:\n",
    "    classificar_mensagem(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Testando com Mensagens em Português\n",
    "\n",
    "Como o modelo foi treinado com mensagens em inglês, precisamos traduzir mensagens em português antes de classificar.\n",
    "\n",
    "**Pipeline para português:**\n",
    "1. Mensagem em português (**texto**)\n",
    "2. Tradução para inglês usando Google Translate (**texto**)\n",
    "3. Pré-processamento (**texto tokenizado**)\n",
    "4. Vetorização TF-IDF (**dados numéricos**)\n",
    "5. Classificação pelo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "tradutor = Translator()\n",
    "\n",
    "def traduzir_mensagem(texto, destino='en'):\n",
    "    try:\n",
    "        resultado = tradutor.translate(texto, dest=destino)\n",
    "        return resultado.text\n",
    "    except:\n",
    "        return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens_teste_pt = [\n",
    "    \"Parabéns! Você ganhou um prêmio de R$ 10.000. Ligue agora para resgatar!\",\n",
    "    \"Oi, vamos nos encontrar para almoçar amanhã?\",\n",
    "    \"URGENTE! Sua conta será bloqueada. Clique aqui imediatamente para verificar.\",\n",
    "    \"Pode comprar leite quando estiver voltando para casa?\",\n",
    "    \"Você foi selecionado para uma oferta especial. Responda SIM para 40404.\",\n",
    "    \"Obrigado pela ajuda ontem, agradeço muito!\"\n",
    "]\n",
    "\n",
    "print('Classificando Mensagens em Português\\n')\n",
    "\n",
    "for msg_pt in mensagens_teste_pt:\n",
    "    print(f'Mensagem original (PT): \"{msg_pt}\"')\n",
    "    msg_en = traduzir_mensagem(msg_pt, destino='en')\n",
    "    print(f'Traduzida (EN): \"{msg_en}\"')\n",
    "    print()\n",
    "    classificar_mensagem(msg_en)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Análise das Palavras Mais Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vetorizador.get_feature_names_out()\n",
    "log_prob_spam = modelo.feature_log_prob_[1]\n",
    "log_prob_ham = modelo.feature_log_prob_[0]\n",
    "\n",
    "indices_spam = np.argsort(log_prob_spam)[-20:]\n",
    "indices_ham = np.argsort(log_prob_ham)[-20:]\n",
    "\n",
    "palavras_spam = [feature_names[i] for i in indices_spam]\n",
    "palavras_ham = [feature_names[i] for i in indices_ham]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "axes[0].barh(range(len(palavras_spam)), [log_prob_spam[i] for i in indices_spam], color='#e74c3c')\n",
    "axes[0].set_yticks(range(len(palavras_spam)))\n",
    "axes[0].set_yticklabels(palavras_spam)\n",
    "axes[0].set_xlabel('Log Probabilidade')\n",
    "axes[0].set_title('Top 20 Palavras Associadas a SPAM')\n",
    "\n",
    "axes[1].barh(range(len(palavras_ham)), [log_prob_ham[i] for i in indices_ham], color='#2ecc71')\n",
    "axes[1].set_yticks(range(len(palavras_ham)))\n",
    "axes[1].set_yticklabels(palavras_ham)\n",
    "axes[1].set_xlabel('Log Probabilidade')\n",
    "axes[1].set_title('Top 20 Palavras Associadas a NÃO SPAM')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
